{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1Ko4ToXqpV2VedkA09_OEBABECLi4pA7z",
      "authorship_tag": "ABX9TyMOle008Fpjb61/6lr3G53C"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "it-RFE2aC730",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6da036b-8d01-4681-d186-40e572873683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec  5 04:23:36 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   28C    P0              45W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWEhcDLbDzSP",
        "outputId": "08f102d8-b830-4252-9ff3-702b1a4889bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom\n",
        "!pip install pytorch_msssim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zlUCUXMEUVj",
        "outputId": "91667391-03b8-4c95-8d76-f15ad8ccb53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/2.4 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-3.0.1\n",
            "Collecting pytorch_msssim\n",
            "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch_msssim) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->pytorch_msssim) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch_msssim) (3.0.2)\n",
            "Downloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
            "Installing collected packages: pytorch_msssim\n",
            "Successfully installed pytorch_msssim-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 손실 함수 정의\n",
        "def mle_loss(E_psi, E_phi, z_x, z_y, z_yx_T, z_xy_T):\n",
        "    L_YX = E_psi(z_x) - E_psi(z_yx_T)\n",
        "    L_XY = E_phi(z_y) - E_phi(z_xy_T)\n",
        "    return L_YX, L_XY\n",
        "\n",
        "def consistency_loss(E_psi, E_phi, z_yx_T, z_xy_T):\n",
        "    L1_YXY = E_psi(z_yx_T) - E_phi(z_yx_T)\n",
        "    L2_YXY = E_phi(z_xy_T) - E_psi(z_xy_T)\n",
        "    L_C = L1_YXY + L2_YXY\n",
        "    return L_C\n",
        "\n",
        "def total_loss(E_psi, E_phi, z_x, z_y, z_yx_T, z_xy_T, gamma=0.1):\n",
        "    L_YX, L_XY = mle_loss(E_psi, E_phi, z_x, z_y, z_yx_T, z_xy_T)\n",
        "    L_C = consistency_loss(E_psi, E_phi, z_yx_T, z_xy_T)\n",
        "    total_loss = L_YX + L_XY + gamma * L_C\n",
        "    return total_loss, L_YX, L_XY, L_C\n",
        "\n",
        "# 학습 루프\n",
        "def train_model(model, data_loader, optimizer, epochs=50, gamma=0.1):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for batch_idx, (source, target) in enumerate(data_loader):\n",
        "            source, target = source.cuda(), target.cuda()\n",
        "\n",
        "            # Forward pass\n",
        "            z_x, z_y, z_yx_T, z_xy_T = model(source, target)\n",
        "\n",
        "            # Loss calculations\n",
        "            L_YX = model.E_psi(z_x).mean() - model.E_psi(z_yx_T).mean()\n",
        "            L_XY = model.E_phi(z_y).mean() - model.E_phi(z_xy_T).mean()\n",
        "            L_C1 = model.E_psi(z_yx_T).mean() - model.E_phi(z_yx_T).mean()\n",
        "            L_C2 = model.E_phi(z_xy_T).mean() - model.E_psi(z_xy_T).mean()\n",
        "            L_C = L_C1 + L_C2\n",
        "\n",
        "            loss = L_YX + L_XY + gamma * L_C\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # 중간 결과 출력\n",
        "            if batch_idx == 0:\n",
        "                print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_idx+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Total Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "id": "XyrFk46xEu7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pydicom\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dataset definition\n",
        "class GlioblastomaMRIDataset(Dataset):\n",
        "    def __init__(self, pre_dir, post_dir):\n",
        "        self.pre_dir = pre_dir\n",
        "        self.post_dir = post_dir\n",
        "        self.pre_files = sorted(os.listdir(pre_dir))\n",
        "        self.post_files = sorted(os.listdir(post_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pre_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pre_path = os.path.join(self.pre_dir, self.pre_files[idx])\n",
        "        post_path = os.path.join(self.post_dir, self.post_files[idx])\n",
        "        pre_dicom = pydicom.dcmread(pre_path)\n",
        "        post_dicom = pydicom.dcmread(post_path)\n",
        "\n",
        "        pre_image = pre_dicom.pixel_array.astype(np.float32)\n",
        "        post_image = post_dicom.pixel_array.astype(np.float32)\n",
        "\n",
        "        # Normalize pixel arrays\n",
        "        if (pre_image.max() - pre_image.min()) > 0:\n",
        "            pre_image = (pre_image - pre_image.min()) / (pre_image.max() - pre_image.min())\n",
        "        else:\n",
        "            pre_image = np.zeros_like(pre_image)\n",
        "\n",
        "        if (post_image.max() - post_image.min()) > 0:\n",
        "            post_image = (post_image - post_image.min()) / (post_image.max() - post_image.min())\n",
        "        else:\n",
        "            post_image = np.zeros_like(post_image)\n",
        "\n",
        "        pre_image = cv2.resize(pre_image, (256, 256))\n",
        "        post_image = cv2.resize(post_image, (256, 256))\n",
        "\n",
        "        pre_image = torch.tensor(pre_image[None, :], dtype=torch.float32)\n",
        "        post_image = torch.tensor(post_image[None, :], dtype=torch.float32)\n",
        "        return pre_image, post_image\n",
        "\n",
        "# VAE definition\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(128 * 64 * 64, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(128 * 64 * 64, latent_dim)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128 * 64 * 64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        encoded = self.encoder(x).view(x.size(0), -1)\n",
        "        mu = self.fc_mu(encoded)\n",
        "        logvar = self.fc_logvar(encoded)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        z = self.decoder[0](z).view(-1, 128, 64, 64)\n",
        "        return self.decoder[1:](z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstructed = self.decode(z)\n",
        "        return reconstructed, mu, logvar\n",
        "\n",
        "# EBM definition\n",
        "class EBM(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(EBM, self).__init__()\n",
        "        self.energy_net = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, latent_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.energy_net(z)\n",
        "\n",
        "# Loss functions\n",
        "def vae_loss(reconstructed, x, mu, logvar):\n",
        "    recon_loss = nn.MSELoss()(reconstructed, x)\n",
        "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + kl_div\n",
        "\n",
        "def combined_loss(z_s2t, z_t2s, latent_source, latent_target, gamma=0.1):\n",
        "    consistency_loss = nn.MSELoss()(latent_source, z_t2s) + nn.MSELoss()(latent_target, z_s2t)\n",
        "    return gamma * consistency_loss\n",
        "\n",
        "def visualize_results(source, target, predicted_target):\n",
        "    source = source.cpu().detach().numpy()\n",
        "    target = target.cpu().detach().numpy()\n",
        "    predicted_target = predicted_target.cpu().detach().numpy()\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title(\"Source\")\n",
        "    plt.imshow(source[0, 0], cmap='gray')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title(\"Target\")\n",
        "    plt.imshow(target[0, 0], cmap='gray')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title(\"Predicted Target\")\n",
        "    plt.imshow(predicted_target[0, 0], cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "# Initialize weights\n",
        "def init_weights(m):\n",
        "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
        "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "\n",
        "# Training loop\n",
        "def train_cct_ebm(vae, ebm_s2t, ebm_t2s, dataloader, optimizer_vae, optimizer_ebm, epochs, latent_dim):\n",
        "    vae.apply(init_weights)\n",
        "    ebm_s2t.apply(init_weights)\n",
        "    ebm_t2s.apply(init_weights)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        vae.train()\n",
        "        ebm_s2t.train()\n",
        "        ebm_t2s.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch_idx, (source, target) in enumerate(dataloader):\n",
        "            source, target = source.cuda(), target.cuda()\n",
        "            optimizer_vae.zero_grad()\n",
        "            optimizer_ebm.zero_grad()\n",
        "\n",
        "            reconstructed, mu, logvar = vae(source)\n",
        "            z_source = vae.reparameterize(mu, logvar)\n",
        "\n",
        "            _, mu_target, logvar_target = vae(target)\n",
        "            z_target = vae.reparameterize(mu_target, logvar_target)\n",
        "\n",
        "            energy_s2t = ebm_s2t(z_source)\n",
        "            energy_t2s = ebm_t2s(z_target)\n",
        "\n",
        "            vae_recon_loss = vae_loss(reconstructed, source, mu, logvar)\n",
        "            consistency = combined_loss(energy_s2t, energy_t2s, z_source, z_target)\n",
        "\n",
        "            loss = vae_recon_loss + consistency\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer_vae.step()\n",
        "            optimizer_ebm.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            if batch_idx == 0:\n",
        "                visualize_results(source, target, reconstructed)\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss:.4f}\")\n",
        "\n",
        "# Data preparation\n",
        "pre_dir = \"/content/drive/MyDrive/tumorpred/data/train/pre\"\n",
        "post_dir = \"/content/drive/MyDrive/tumorpred/data/train/post\"\n",
        "train_dataset = GlioblastomaMRIDataset(pre_dir, post_dir)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# Model initialization\n",
        "latent_dim = 128\n",
        "vae = VAE(latent_dim).cuda()\n",
        "ebm_s2t = EBM(latent_dim).cuda()\n",
        "ebm_t2s = EBM(latent_dim).cuda()\n",
        "\n",
        "# Optimizers\n",
        "optimizer_vae = optim.Adam(vae.parameters(), lr=1e-4)\n",
        "optimizer_ebm = optim.Adam(list(ebm_s2t.parameters()) + list(ebm_t2s.parameters()), lr=1e-4)\n",
        "\n",
        "# Train the model\n",
        "train_cct_ebm(vae, ebm_s2t, ebm_t2s, train_loader, optimizer_vae, optimizer_ebm, epochs=100, latent_dim=latent_dim)"
      ],
      "metadata": {
        "id": "02kMCLTBXyxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import structural_similarity as ssim\n",
        "import math\n",
        "\n",
        "# Evaluation functions\n",
        "def calculate_psnr(img1, img2):\n",
        "    mse = np.mean((img1 - img2) ** 2)\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    max_pixel = 1.0  # Images are normalized between 0 and 1\n",
        "    psnr = 20 * math.log10(max_pixel / math.sqrt(mse))\n",
        "    return psnr\n",
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total_mse = 0\n",
        "    total_psnr = 0\n",
        "    total_ssim = 0\n",
        "    total_images = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for source, target in dataloader:\n",
        "            source, target = source.to(device), target.to(device)\n",
        "\n",
        "            # Predict\n",
        "            reconstructed, _, _ = model(source)\n",
        "\n",
        "            # Convert tensors to numpy arrays for evaluation\n",
        "            target_np = target.cpu().numpy()\n",
        "            reconstructed_np = reconstructed.cpu().numpy()\n",
        "\n",
        "            for i in range(len(target)):\n",
        "                gt = target_np[i, 0]\n",
        "                pred = reconstructed_np[i, 0]\n",
        "\n",
        "                # Calculate metrics\n",
        "                mse = np.mean((gt - pred) ** 2)\n",
        "                psnr = calculate_psnr(gt, pred)\n",
        "                ssim_value = ssim(gt, pred, data_range=pred.max() - pred.min())\n",
        "\n",
        "                total_mse += mse\n",
        "                total_psnr += psnr\n",
        "                total_ssim += ssim_value\n",
        "                total_images += 1\n",
        "\n",
        "    avg_mse = total_mse / total_images\n",
        "    avg_psnr = total_psnr / total_images\n",
        "    avg_ssim = total_ssim / total_images\n",
        "\n",
        "    print(f\"Evaluation Results:\")\n",
        "    print(f\"Mean Squared Error (MSE): {avg_mse:.4f}\")\n",
        "    print(f\"Peak Signal-to-Noise Ratio (PSNR): {avg_psnr:.2f} dB\")\n",
        "    print(f\"Structural Similarity Index Measure (SSIM): {avg_ssim:.4f}\")\n",
        "\n",
        "# Prepare test dataset and dataloader\n",
        "test_pre_dir = \"/content/drive/MyDrive/tumorpred/data/val/pre\"\n",
        "test_post_dir = \"/content/drive/MyDrive/tumorpred/data/val/post\"\n",
        "test_dataset = GlioblastomaMRIDataset(test_pre_dir, test_post_dir)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(vae, test_loader, device=torch.device(\"cuda\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1evh4brCeM5",
        "outputId": "d54e6ab2-7755-4f07-ee2f-ff06f8aa133d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results:\n",
            "Mean Squared Error (MSE): 0.0216\n",
            "Peak Signal-to-Noise Ratio (PSNR): 16.87 dB\n",
            "Structural Similarity Index Measure (SSIM): 0.2281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import sqrtm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "# Load pre-trained InceptionV3 model\n",
        "def load_inception_model():\n",
        "    model = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))\n",
        "    return model\n",
        "\n",
        "# Resize and preprocess images\n",
        "def preprocess_images(images):\n",
        "    images_resized = []\n",
        "    for img in images:\n",
        "        img_resized = tf.image.resize(img, (299, 299)).numpy()\n",
        "        img_preprocessed = preprocess_input(img_resized)\n",
        "        images_resized.append(img_preprocessed)\n",
        "    return np.array(images_resized)\n",
        "\n",
        "# Calculate FID\n",
        "def calculate_fid(real_images, generated_images, model):\n",
        "    # Preprocess images\n",
        "    real_images = preprocess_images(real_images)\n",
        "    generated_images = preprocess_images(generated_images)\n",
        "\n",
        "    # Calculate feature embeddings\n",
        "    real_features = model.predict(real_images)\n",
        "    gen_features = model.predict(generated_images)\n",
        "\n",
        "    # Calculate mean and covariance\n",
        "    mu_real, sigma_real = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n",
        "    mu_gen, sigma_gen = np.mean(gen_features, axis=0), np.cov(gen_features, rowvar=False)\n",
        "\n",
        "    # Calculate squared difference between means\n",
        "    diff = mu_real - mu_gen\n",
        "    diff_squared = np.sum(diff**2)\n",
        "\n",
        "    # Calculate the trace of the product of covariance matrices\n",
        "    covmean = sqrtm(sigma_real.dot(sigma_gen))\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "\n",
        "    fid = diff_squared + np.trace(sigma_real + sigma_gen - 2 * covmean)\n",
        "    return fid\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load real and generated images (shape: [N, H, W, C])\n",
        "    # Replace these with your real and generated image arrays\n",
        "    real_images = np.random.rand(100, 256, 256, 3)\n",
        "    generated_images = np.random.rand(100, 256, 256, 3)\n",
        "\n",
        "    # Load InceptionV3 model\n",
        "    inception_model = load_inception_model()\n",
        "\n",
        "    # Calculate FID\n",
        "    fid_value = calculate_fid(real_images, generated_images, inception_model)\n",
        "    print(f\"FID: {fid_value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyRiTxqJXpf5",
        "outputId": "99d6c15e-c6de-428f-d75e-56089fb40795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "FID: 0.0233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cMn1cDagXpRr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}